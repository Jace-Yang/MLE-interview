# DeepWalk[2014] & GCN[2016]

## 一、DeepWalk

DeepWalk是来解决图里面**节点embedding**问题的。Graph Embedding技术将图中的节点以低维稠密向量的形式进行表达，要求在原始图中**相似**(不同的方法对相似的定义不同)的节点其在低维表达空间也接近。得到的表达向量可以用来进行下游任务，如节点分类(node classification)，链接预测(link prediction)等。

#### DeepWalk 算法原理

虽然DeepWalk是KDD 2014的工作，但却是我们了解Graph Embedding无法绕过的一个方法。

我们都知道在NLP任务中，word2vec是一种常用的word embedding方法，word2vec通过语料库中的句子序列来描述词与词的共现关系，进而学习到词语的向量表示。

DeepWalk的思想类似word2vec，使用**图中节点与节点的共现关系**来学习节点的向量表示。那么关键的问题就是如何来描述节点与节点的共现关系，DeepWalk给出的方法是使用**随机游走(RandomWalk)**的方式在图中进行节点采样。

RandomWalk是一种**可重复访问已访问节点的深度优先遍历算法**。给定当前访问起始节点，从其邻居中随机采样节点作为下一个访问节点，重复此过程，直到访问序列长度满足预设条件。

获取足够数量的节点访问序列后，使用**skip-gram**进行向量学习，这样能够把握节点的**共现信息**。



## 二、GCN

### 2.1 为啥要用GCN

GCN的概念首次提出于ICLR2017：SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS。

**对于图结构的数据，CNN、RNN都无法解决。**我们做图像识别，对象是图片，是一个二维的结构，于是人们发明了CNN的卷积核来提取图片特征。卷积核是一个个小窗口，在图片上平移，通过卷积的方式来提取特征。这里的关键在于图片结构上的**平移不变性**：一个小窗口无论移动到图片的哪一个位置，其内部的结构都是一模一样的，因此CNN可以实现**参数共享**。这就是CNN的精髓所在。

再回忆一下RNN系列，它的对象是自然语言这样的序列信息，是一个一维的结构，RNN就是专门针对这些序列的结构而设计的，通过各种门的操作，使得序列前后的信息互相影响，从而很好地捕捉序列的特征。

上面讲的图片或者语言，都属于**欧式空间**的数据，因此才有维度的概念，欧式空间的数据的特点就是结构很规则。但是现实生活中，其实有很多很多不规则的数据结构，典型的就是图结构，或称拓扑结构，如社交网络、知识图谱、分子结构等等。

图的结构一般来说是十分不规则的，可以认为是**无限维**的一种数据，所以它**没有平移不变性**。每一个节点的周围结构可能都是独一无二的，这种结构的数据，就让传统的CNN、RNN瞬间失效。

GCN，图卷积神经网络，实际上跟CNN的作用一样，**就是一个特征提取器，只不过它的对象是图数据**。GCN精妙地设计了一种从图数据中提取特征的方法，从而让我们可以使用这些特征去对图数据进行：

- 节点分类（node classification）
- 图分类（graph classification）
- 链接预测（link prediction）
- 还可以顺便得到图的embedding表示（graph embedding）

### 2.2 GCN的核心公式

假设我们手头有一批图数据，其中有N个节点（node），每个节点都有自己的特征embedding，我们设这些节点的特征组成一个N×D维的矩阵$X$，然后各个节点之间的**关系**也会形成一个N×N维的矩阵A（就是邻接矩阵）

GCN也是一个神经网络层，它的层与层之间的传播方式是：

![img](https://pic3.zhimg.com/50/v2-94c7d5014d9e9bcf81f630831cf9d9f0_720w.jpg?source=1940ef5c)

这个公式中：

- $\widetilde A = A+I$，$I$是单位矩阵。
- $\widetilde D $是度矩阵（degree matrix），$D[i][i]$就是节点i的度。
- H是每一层的特征，对于第一层输入层的话，$H^{(1)}$就是$X$。
- σ是非线性激活函数

我们先不用考虑为什么要这样去设计一个公式。我们现在只用知道： ![[公式]](https://www.zhihu.com/equation?tex=%5Cmathbf%7B%5Ctilde%7BD%7D%5E%7B-%5Cfrac%7B1%7D%7B2%7D%7D+%5Ctilde%7BA%7D+%5Ctilde%7BD%7D%5E%7B-%5Cfrac%7B1%7D%7B2%7D%7D%7D) 这个部分，**是可以事先算好的**。

所以对于不需要去了解数学原理、只想应用GCN来解决实际问题的人来说，你只用知道：哦，这个GCN设计了一个牛逼的公式，用这个公式就可以很好地提取图的特征。

为了直观理解，我们用论文中的一幅图：

![img](https://pic1.zhimg.com/50/v2-6aebc0dd82beeb43291291b01e63003a_720w.jpg?source=1940ef5c)![img]



上图中的GCN输入一个图，通过若干层GCN每个node的特征从X变成了Z，但是，无论中间有多少层，**node之间的连接关系，即A，都是共享的**。

假设我们构造一个两层的GCN，激活函数分别采用ReLU和Softmax，则整体的正向传播的公式为：

![img](https://pic3.zhimg.com/50/v2-0d0b5154661ea285155125dfe022001f_720w.jpg?source=1940ef5c)

最后，我们**针对所有带标签的节点计算cross entropy损失函数**：

![img](https://pic1.zhimg.com/80/v2-7fb710149829c808a0ac275018a26176_1440w.jpg?source=1940ef5c)

就可以训练一个node classification的模型了。由于即使只有很少的node有标签也能训练，作者称他们的方法为**半监督分类**。

当然，你也可以用这个方法去做graph classification、link prediction，只是把损失函数给变化一下即可。



### 2.3 GCN为啥是这个亚子

我们的每一层GCN的输入都是**邻接矩阵A**和**node的特征H**，那么我们直接做一个内积，再乘一个参数矩阵W，然后激活一下，就相当于一个简单的神经网络层嘛，是不是也可以呢？

![img](https://pic3.zhimg.com/50/v2-a4b9b17168017254b9ab3eb3c021d168_720w.jpg?source=1940ef5c)

实验证明，即使就这么简单的神经网络层，就已经很强大了。但是这个简单模型有几个局限性：

- 只使用A的话，由于A的对角线上都是0，所以在和特征矩阵H相乘的时候，只会计算一个node的**所有邻居**的特征的加权和，该node自己的特征却被忽略了。因此，我们可以做一个小小的改动，给A加上一个单位矩阵I，这样就让对角线元素变成1了。
- A是没有经过归一化的矩阵，这样与特征矩阵相乘会改变特征原本的分布，产生一些不可预测的问题。所以我们对A做一个标准化处理。首先让**A的每一行加起来为1**，我们可以乘以一个 ![[公式]](https://www.zhihu.com/equation?tex=D%5E%7B-1%7D) ，D就是度矩阵（因为$D[i][i]$其实就是A每行的和）。我们可以进一步把 ![[公式]](https://www.zhihu.com/equation?tex=D%5E%7B-1%7D) 拆开与A相乘，得到一个对称且归一化的矩阵： ![[公式]](https://www.zhihu.com/equation?tex=D%5E%7B-1%2F2%7DAD%5E%7B-1%2F2%7D) 。

通过对上面两个局限的改进，我们便得到了最终的层特征传播公式：

![img](https://pic2.zhimg.com/50/v2-cbf3846db7e8db2a3e2b4122f6755a6c_720w.jpg?source=1940ef5c)

### 2.4 效果

**即使不训练，完全使用随机初始化的参数W，GCN提取出来的特征就以及十分优秀了！**这跟CNN不训练是完全不一样的，后者不训练是根本得不到什么有效特征的。作者做了一个实验，使用一个俱乐部会员的关系网络，使用随机初始化的GCN进行特征提取，得到各个node的embedding，然后可视化：

![img](https://pic1.zhimg.com/80/v2-809cc6f4a68d0da2cd8f061d1aa3659e_1440w.jpg?source=1940ef5c)

而这种聚类结果，可以和DeepWalk、node2vec这种经过复杂训练得到的node embedding的效果媲美了。

还没训练就已经效果这么好，那**给少量的标注信息，GCN的效果就会更加出色（半监督学习）**。

