# EM算法

### 0x01. 预备知识

#### 1. 极大似然估计

（1）举例说明：经典问题——学生身高问题

我们需要调查我们学校的男生和女生的身高分布。 假设你在校园里随便找了100个男生和100个女生。他们共200个人。将他们按照性别划分为两组，然后先统计抽样得到的100个男生的身高。假设他们的身高是服从正态分布的。但是这个分布的均值 μ  和方差 σ^2 我们不知道，这两个参数就是我们要估计的。记作 θ = [ μ , σ ]
  
问题数学化. 设样本集 X = x1 , x2 , … , xN，其中 N = 100，p ( x i ∣ θ ) 为概率密度函数，表示抽到男生身高为xi 的概率。由于100个样本之间独立同分布，所以我同时抽到这100个男生的概率就是他们各自概率的乘积，也就是样本集 X中各个样本的联合概率，用下式表示：



这个概率反映了，在概率密度函数的参数是 θ 时，得到 X 这组样本的概率。 我们需要找到一个参数 θ ，使得抽到 X 这组样本的概率最大，也就是说需要其对应的似然函数 L(θ) 最大。满足条件的 θ 叫做 θ 的最大似然估计量，记为 θ′ = argmax L(θ)

求最大似然函数估计值的一般步骤：

- 首先，写出似然函数
- 然后，对似然函数取对数：
- 接着，对上式按 θ 求导，令导数为0，得到似然方程；
- 最后，求解似然方程，得到的参数 θ 即为所求。



## 0x02. EM算法步骤

1、初始化分布参数 θ； 重复E、M步骤直到收敛：
2、E步骤：根据现在的参数θ，来计算出隐性变量(如类别)的后验概率（即隐性变量的期望），作为隐性变量的现估计值：

3、M步骤：将似然函数最大化以获得新的参数值θ ,即更新θ 

举例
两种硬币，但是两个硬币的材质不同导致其出现正反面的概率不一样。目前我们只有一组观测数据，要求出每一种硬币投掷时正面向上的概率。总共投了五轮，每轮投掷五次
1、现在先考虑一种简单的情况，假设我们知道这每一轮用的是哪一个硬币去投掷的：

那么我们拿着这样的一组数据，就可以很轻松的估计出A硬币和B硬币出现正面的概率，如下：
P A = ( 3 + 1 + 2 ) / 15 = 0.4 P B = ( 2 + 3 ) / 10 = 0.5

2、现在把问题变得复杂一点，假设我们不知道每一次投掷用的是哪一种硬币，等于是现在的问题加上了一个隐变量，就是每一次选取的硬币的种类。

那么现在可以想一想，假设我们把每一次硬币的种类设为z,则这五次实验生成了一个5维的向量( z 1 , z 2 , z 3 , z 4 , z 5 ) (z1,z2,z3,z4,z5)(z1,z2,z3,z4,z5)，现在问题来了，如果我们要根据观测结果去求出PA,PB，那么首先需要知道z，但是如果用最大似然估计去估计z，又要先求出PA,PB。这就产生了一个循环。

那么这个时候EM算法的作用就体现出来了! EM算法的基本思想是：先初始化一个PA,PB(就是上文的θ \thetaθ)，然后我们拿着这个初始化的PA,PB用最大似然概率估计出z，接下来有了z之后就用z去计算出在当前z的情况下的PA,PB是多少，然后不断地重复这两个步骤直到收敛。

有了这个思想之后现在用这个思想来做一下这个例子，假设初始状态下PA=0.2, PB=0.7，然后我们根据这个概率去估计出z：

标粗体的是按最大似然估计，最有可能的硬币种类。
按照最大似然估计，z=(B,A,A,B,A)，有了z之后我们反过来重新估计一下PA,PB：
PA = （2+1+2）/15 = 0.33
PB =（3+3）/10 = 0.6

可以看到PA,PB的值已经更新了，假设PA,PB的真实值0.4和0.5，那么你在不断地重复这两步你就会发现PA,PB在不断地靠近这两个真实值。


EM算法在GMM、K-means中有应用。